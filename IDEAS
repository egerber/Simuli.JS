So far a Model was implemented to learn the mapping from input(t) -> input(t+1). This implementation should be altered in order to perform a more general mapping from input(t) -> output(t) where output(t) can be input(t+1) as well. This would create the opportunity to easily build hierarchies of models. The goal is to arrive at a model that makes predictions by means of a very limited set of patterns. These patterns are provided by lower level models. 
Example: The input is of length 50. The goal is to predict the input of the next timestep. So far, the model can learn to build the correct synapses between input(t) and input(t+1) in order to find a stable transition and be able to make a solid prediction. However this requires a lot of synapses (e.g. 10 synapses per input item, 50 in this example). Furthermore, the learned predictions will have no value when a different type of input pattern is applied. Also when we look at cellular automata, this approach seems not smart, since the amount of rules for the pattern is very limited. 
Ideally the model should come up with more "compressed" patterns, that is less synapses and more globally used patterns. Optimally, these patterns should hold some value when a new input pattern is applied.
This could be achieved by building up a hierarchy of models. For the example with 50 inputs, this could look like this:
The first layer creates k (e.g. 10) m:n models (e.g. 10:3, inputs to outputs). The selection of these models (or patterns) is according to how useful they are in making correct predictions. The patterns then would be used by layer 2, which optmizes as well as the selection of patterns to be used for the prediction of a specific input item, as well as which inputs from t+1 are passed into a pattern and which corresponding input item is connected to it. The patterns on layer 1 would be optimized based on how well the performance on layer 2 is. 
-> somehow, layer 2 must make prediction by EITHER choosing from a limited set of patterns OR choosing a limited number of patterns from a large set (including specific synapses)



The current implementation defines 0 and 1 as two different states, without attributing any meaning to them. This makes it hard to encode patterns. It is impossible to define a unit that receives multiple input and outputs whether one specfic input configuration applied (e.g. 0001101). This is only possible if we define the output state 1 as a boolean indicator for the existence of a pattern. 
-> I could implement a unit that is given k random inputs and that learns to output 1 for the most frequent input configuration that is receives. The following layer could use this information in order to make valid predictions. The predictions could again refer to some pattern. e.g. pattern_1(t)->pattern_25(t+1)

-> How could fuzziness be introduced to this approach without introducing probabilities or specifying the minimal number of matching inputs for a pattern (e.g output 1 if at least 4 out of 5 inputs match)
	-> OR method: fire if the inputs match to any of multiple configurations



How does the neural information processing work?
-> The dendrites of a neuron receive inputs from nearby neurons. This input is binary and either states activation or no activation. If multiple dendrites receive activation at about the same time, the receiver-neuron sends activation to other neurons. The connection from the sending neurons will be strengthened.
Thereby the output from a neuron indicates whether it has received enough input at the time.



A pattern as a specific combination of values has no meaning in itself. It is easy to detect frequent combination of values in a stream of input. But it is much harder to find frequent transitions of patterns 
Now the problem that poses is the following: How do I optimize at the same time the definition of useful patterns as well as the selection from these patterns in order to make strong predictions?

-unit should set all internal_states and get all internal_states by generic method
-unit should should be able to add connections and choose among a certain set of surrounded units (e.g. local relationship).
-units should only be varying with regard to their input(s) and output, how the input to output behavior is defined, and how updates are performed (internal parameters are changed and reconnections are formed)

--- 

-think of a different encoding for logs
e.g. for events it is better in the following manner: {event_name:event1, id:12, timesteps:[10,11,12,13,14,etc]} instead of {t:10,id:12,event_name:event1}

-look for solid visualualization package (filter functions in the manner of simulinks analyzer, zooming etc.) that can be extended with individual packages. 
(OR at least some package with functionality for filtering data)

----

Give unit not only access to local state object but also to global state reference
-> approximate behavior of ressource access

dirtybit could be used to indicate newly created cells as well as well as newly formed connections
00 (0) - no changes 
01 (1) - connection changed
10 (2) - cell was newly added
11 (3) - cell was added and new connections applied

---------------

delay lines
- e.g. delayed feedback
-> general: make it possible to define in which order the nodes are calculated and the delay of communication between nodes
	-delay 0: same timestep calculation
	-delay k: value is passed over in next timestep (for k>=1)
	-> allows to built graph of the whole network and bring the network into a different shape
	connection(src,target,mapping,delay=0)
---------------

Build units from collection of pre-existing neurons
- e.g. neuron with 10 synapses becomes one unit (synapses are input units, neuron is output unit)

----

Abandon local references:
- everything is referenced by index -> index is resolved by Factory method
- create and delete 
- get inputs() resolves index references to objects
- connections are saved as graph by public object (makes it easier and more efficient to find links e.g. triggering all on_deletes)
- possibly: keep objects as a method to setup a network, internally convert everything to arrays and array methods

- can I create a new class by means of a specification?


Define
- generate_feedback(input,output, state)
- forward_feedback(input,output, state, feedback_given)
Feedback is sent after all feedback values where received
 -> how can this be enforced?



 UNIT:
 get count_inputs
 - input_slots (e.g. 5)
 - dim_output (e.g. 0, [0], [1,1])

allow to define feedback and feedforward connections explicitly
- connect(type: feedback | feedforward | bidirectional)
- feedforward/feedback lines with delay

compute_feedback (regardless of feedback_given)
tick() does not trigger feedback sending implicitly
	- tick() of system invokes send feedback calls in correct order

Spatial Connections (e.g 2D Input Array)

Network
- specify how the input of a network is transformed into the activation of the Input Group
- specify how the output of the network is computed by means of the network activation

- optional: transform_input(inputs) -> returns array which is passed to inputs
- optional: compute_output(groups) referencing groups

set_feedback_component
set feedback

feedback_inputs (indicate from where to receive feedback)
feedback_outputs (indicate where to send feedback signal to)

compute_feedback ~ output,state

apply_feedback ~ output, state, feedback

compute_feedback(my_output, target_output,state)

save InAdj List
save OutAdj List

network topology not possible for cyclic graph
-> all connections must be acyclic (big constraint)
-> consider the order of creation, the later create, the higher order ()
-> members in groups cannot be acyclical

Is there a use of cyclical connections since cyclical feedback connections are possible?
- all cyclical connections can be functionally resolved in a non cyclical form

FIANAL GOAL
- completely indexed based system, remove all instances,

- convert the whole system away from a object notation and perform matrix operations

for all elements of network part compute
- output(state,input,etc.)

requires
- order all nodes into groups of the same hierarchy (topolgy)
- for each group, provide all input values necessary (input_values)
	- retrieve all states of the group
	- output -> compute_feedback(input_values, state) for all members of the group
	- save outputs to network activation values

? What is the complexity of recalculating the topololgy of a network, given a connection change?


schema	
	-tick()
	-compute_output
	-compute_feedback
	-apply_feedback
	-on_input_changed
	-events
	-feedforward-inputs
	-feedback-inputs
network_schema extends:
	-groups
	-create
	-select

network instances (ordered by schema)
	-states[]
	-current_outputs[]
	-graph (ff inputs, fb inputs)


session saves
- units by type: {type: indices}
- units by group: {name: indices}
- units 

for all groups in hierarchy (descending)
	for all group members
		for all feeback inpus
			apply_feedback(compute_feedback(current_outputs[member], current_outputs[feedback_input], state[feedback_input])
for all groups in hierarchy ascending
	for all group members
		tick(state[member])
		handle_events[member]
		output <- compute_output(current_outputs[inputs])

problems:
	-how to pass object reference to unit in events (e.g. for calling ref.create("dfdfa",{}, etc.))
		-> network builds sub topology
		-> create, select is method of that topology and adds
		-> network instance exists

add_connection(x,y)
- case 1: (x < y)
	nothing
- case 2: (x > y && no cycle)
- case 3: (x > y && creates cycle)

remove_connection(x,y)
- case 1 (cycle resolved)
- case 2 (no cycle existed)
	- nothing


Problems:
- network provides functions select, create,etc.
	->provide create and select method inside event (or: as part of state)
- network allows to access components and set inputs (e.g. component1.inputs=component2)			(SOLVED)
	-> NEVER ALLOW DIRECT ACCESS TO A COMPONENT, ONLY WORK WITH SIGNALS
-compute feedback and provide to be accessed my component itself current_feedbacks[]
	-> Pre-catch values and feed into functions

global fields
- inputs[id]=[id1,id2,id3]
- feedback_inputs[i]=[idx,idy,idz]
- states[i]={prop1,prop2,prop3}
- schemas[i]={compute_feedback, compute_output, events,...}

What is the advantage of this whole approach?
- less recursion
- better control over flow of information
- less memory
- faster?



Ideally connect items in the following manner
- network.select("type", cirteria_xyz).connect(network.select("type",...), type="bidirectional",reset_ports=false)


Connection
- from (label or array)
- to (label or array)
- type (feedforward or feedback)
- reset_slots (true or false)
- mapper (Selection from mappers or own mapper -> returns (i,j) for all given items (i, j refer to index positions within array or group))
- signal_delay (0 - forward signal at same timestep, 1 - forward signal at next timestep, k - forward signal after k time steps)#
- [frequency] (forward signal every k timesteps?)

graph can compute groups that can be computed parallel

Session could save links (from,to,delay) and provide all input values to respective sessions
- calling 


nesting:
- create subgraph in graph
- if index of node could not be found
	- forward call to sub graph


General algorithm
check events

FEEDBACK
- acquire all feedback values (compute_feedback())
- call apply_feedback
FEEDFORWARD
- acquire all output values from previous step
- call compute_output


save inputs as adjacency matrix
{
	0: 1,2,3,4,5
	1: ...
}


delay adjacency matrix
{
	0: 0,0,0,0,1,
	1: ...
}

provide all inputs
{
	0: [10,100,145,267],
	...
}

for all elements (grouped by schema) call
- compute_output -> save result
	-> problem: for delay=0 must call item in order
		-> do not allow delay=0
		-> 
same for feedback



push inputs onto component, instead of setting specific ports


Problem: how to notify deletion of connection?


Istead of storing seperate fields of unit in different arrays use one array of various objects
- var components=[
{schema:network_spec, state={timestep:0, count_slots:4}, current_output: 10, last_output:100}
{schema:synapse_spec, state={timestep:0, count_slots:1}, current_output: 1, last_output:-10}
]

save topology as array: [0,10,20,21,22,23,...]

Save Network as the category "SubSystems"

Components can access a public state as well as a attributes object that is shared among all components of the same type

Const state attributes (e.g max_slots inputs -> overriding accessor, make writeable only (__const_variables, __dynamic properties))


--------------
Pseudocode for running indexed version

//tick
for id of ids
	components[id].state.timestep++;
	if(components[id].schema.condition(state)){
		if(schema==network)
			component[id].schema.action(state,create_func,select_func)
	}

for id of ids
	last_output[id]=current_output[id]
	current_output=new Array() //or do not touch 

for id of components orderBy topology
	input_values=new Array(count_input_values)
		for input_id of inputs
			if(delayed)
				input[]=last_output[]
			else
				input[]=current_output[]
	
	current_output[id]=component[id].schema.compute_output();

- same for feedback

replace init_state by state

create spatial sensitive groups (e.g. Multidimensional arrays for images)
- allow connections to be formed with regard to the spatial extent of the image

connection object works with selection object
selection object has
- elements[]
- select() - ? (sort instead)
- filter

specify the ports of two elements that connect with each other
- group_connection (maps between elements of 2 groups)
- component_connection (maps between elements of 1 groups and ports of element)

should connections be saved in a different format? 

ConnectionManager
- add_connection()
- remove()


No need for System component()
Instead: allow how to set inputs in network component
- 

----------------

s1.connect(s2)
- specify port reset
- specify type
	- connect_feedforward(s2)
	- connect_feedback(s2)
	- connect_bidirectional(3)
- specify mapping
	- (i,j)=>true
	- probabilistic
	- probabilistic based on state

	- (state1,state2)=>state1.x - state2.y + Math.random()
	-> every target should be hit exactly once from random source 
		-
	-> how to specify connection to a port
		- 
		elemenent1.connect()

		{	
			target:
			type:
			mapping:
			reset
			method: append_until full/override_when_full
		}

how to unset connections?
	- selection.unconnect(type,(state1, state2)=>true)
	- selection.unconnect(selection2, type) //remove all connections from 
Ports should be able to be targeted explicitly
- 

Ports are in some way another layer of abstraction: Ports -> component -> group

want something like

element1.connect_to(element2, port=1)
and 

selection1.connect(selection2, feedforward, (i,j)=>true, reset_existing_connections)
component1.connect(component2, feeforward, port)

selection1.unconnect(type, (state1,state2)=>true)
selection1.unconnect(selection2, type,)

----------------

ConnectionLogger
- tracks the nodes and connectivity of all elements in the system

ActivationLogger
- tracks feedback states  and output states

StateLogger
- tracks state variables overtime

EventLogger
- logs the occurence of special events in the component
-> later



All Logging is done according to a selector

e.g. 

.monitor_state(select("group0"), ["my_var1", "my_var2"],interval);
.monitor_state(select("group1"), ["my_var2", "my_var3"],interval);

.monitor_activation(selectAll(), "feedforward",interval);
.monitor_structure()

selector for monitor should have following options:
- select by schema -> e.g ["integrators"]
- seÄºect by group e.g. ["my_group_1"]